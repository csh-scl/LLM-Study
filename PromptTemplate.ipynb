{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csh-scl/LLM-Study/blob/main/PromptTemplate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai langchain langchain-openai\n",
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "EBFyoFPb-_7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d76d9fb4-9c41-46b5-ea2c-0aae83e3878a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.62)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.42)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qhh9fyI8-d9v"
      },
      "outputs": [],
      "source": [
        "#API KEY ì €ì¥ì„ ìœ„í•œ os ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ\n",
        "import os\n",
        "\n",
        "#ê¸°ë³¸ LLM ë¡œë“œë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "#ì±„íŒ… LLM ë¡œë“œë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#OPENAI APIí‚¤ ì €ì¥\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'Your API Key'"
      ],
      "metadata": {
        "id": "9F6f494n-IWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------"
      ],
      "metadata": {
        "id": "DczHm9qI994V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Davinch-003 ëª¨ë¸ ì„¤ì •í•˜ê¸°"
      ],
      "metadata": {
        "id": "THkva8fB-C0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "davinch3 = OpenAI(\n",
        "    model_name=\"text-davinci-003\",\n",
        "    max_tokens = 1000\n",
        ")"
      ],
      "metadata": {
        "id": "uqur0akRHi0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ccc734f-87d2-458c-9d89-07c177c83179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-349a1428bdbb>:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  davinch3 = OpenAI(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (1) í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë§›ë³´ê¸°"
      ],
      "metadata": {
        "id": "QhCfB_lQ-uqx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì€ í¬ê²Œ 2ê°€ì§€ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
        "1. Prompt Template\n",
        "2. Chat Prompt Template\n",
        "\n",
        "1ë²ˆ Prompt Templateì€ ì¼ë°˜ì ì¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ìƒì„±í• ë•Œ í™œìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "2ë²ˆ Chat Prompt Templateì€ ì±„íŒ… LLMì— í”„ë¡¬í”„íŠ¸ë¥¼ ì „ë‹¬í•˜ëŠ” ë°ì— í™œìš©í•  ìˆ˜ ìˆëŠ” íŠ¹í™” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì…ë‹ˆë‹¤.\n",
        "\n"
      ],
      "metadata": {
        "id": "LrfEmGR5Ctbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
        "\n",
        "#í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ í†µí•´ ë§¤ê°œë³€ìˆ˜ ì‚½ì… ê°€ëŠ¥í•œ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
        "string_prompt = PromptTemplate.from_template(\"tell me a joke about {subject} {price}\")\n",
        "\n",
        "#ë§¤ê°œë³€ìˆ˜ ì‚½ì…í•œ ê²°ê³¼ë¥¼ string_prompt_valueì— í• ë‹¹\n",
        "string_prompt_value = string_prompt.format_prompt(subject=\"soccer\", price = 10000)\n",
        "\n",
        "#ì±„íŒ…LLMì´ ì•„ë‹Œ LLMê³¼ ëŒ€í™”í•  ë•Œ í•„ìš”í•œ í”„ë¡¬í”„íŠ¸ = string prompt\n",
        "string_prompt_value"
      ],
      "metadata": {
        "id": "-bX3Wvsy-tyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e6169d7-5814-42fe-9da5-a69a67b3933b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text='tell me a joke about soccer 10000')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to_string() í•¨ìˆ˜ë¥¼ í†µí•´ prompt templateìœ¼ë¡œ ìƒì„±í•œ ë¬¸ì¥ raw_text ë°˜í™˜ ê°€ëŠ¥\n",
        "print(string_prompt_value.to_string())"
      ],
      "metadata": {
        "id": "6F3GCMX7-7j8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "457a2145-15b9-4a62-a106-19ecf9631350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tell me a joke about soccer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt = ChatPromptTemplate.from_template(\"tell me a joke about {subject}\")\n",
        "chat_prompt_value = chat_prompt.format_prompt(subject=\"soccer\")\n",
        "chat_prompt_value"
      ],
      "metadata": {
        "id": "vylmSAk2_dfk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c920c9b-5020-4bb6-89b5-5e5c2ad925a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content='tell me a joke about soccer', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
        "string_prompt = PromptTemplate.from_template(\"Could you recommend {subject} nearby {price}?\")\n",
        "string_prompt_value = string_prompt.format_prompt(subject= \"food\", price=10000)\n",
        "\n",
        "# OpenAI LLM ìƒì„± (API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ìœ¼ë¡œ ì¸ì‹)\n",
        "llm = OpenAI()\n",
        "\n",
        "# í”„ë¡¬í”„íŠ¸ ì‹¤í–‰\n",
        "response = llm.invoke(string_prompt_value.to_string())\n",
        "\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "nIma_sYw6G95",
        "outputId": "761ca53b-07e7-4c1d-f943-42b008f09b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'food' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5a577bf47dba>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstring_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could you recommend {subject} nearby {price}?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstring_prompt_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_prompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# OpenAI LLM ìƒì„± (API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ìœ¼ë¡œ ì¸ì‹)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'food' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt_value.to_string()"
      ],
      "metadata": {
        "id": "47q4Uy2y_bM8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd7899dc-bbb7-4b93-db6f-4e6b7c047b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: tell me a joke about soccer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (2) í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í™œìš©í•´ë³´ê¸°"
      ],
      "metadata": {
        "id": "jVF-pxeUE4JI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë°˜ë³µì ì¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚½ì…í•´ì•¼í•˜ëŠ” ê²½ìš°, Prompt Templateë¥¼ í†µí•´ ê°„í¸í•˜ê²Œ LLMì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "RIoNBQ_HFNlm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- GPT-3ì™€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ í™œìš©í•˜ì—¬ ëŒ€í™”í•´ë³´ê¸°"
      ],
      "metadata": {
        "id": "25dmtYfJajHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "ë„ˆëŠ” ìš”ë¦¬ì‚¬ì•¼. ë‚´ê°€ ê°€ì§„ ì¬ë£Œë“¤ì„ ê°–ê³  ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ë¥¼ ì¶”ì²œí•˜ê³ , ê·¸ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ì œì‹œí•´ì¤˜.\n",
        "ë‚´ê°€ ê°€ì§„ ì¬ë£ŒëŠ” ì•„ë˜ì™€ ê°™ì•„.\n",
        "\n",
        "<ì¬ë£Œ>\n",
        "{ì¬ë£Œ}{ìˆ˜ëŸ‰}ê°œ\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "p1urKI18_bxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt_template.format(ì¬ë£Œ = 'ìŒ€, ì¹˜í‚¨, ë„ˆêµ¬ë¦¬'))"
      ],
      "metadata": {
        "id": "lhBbXyEWGGE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1832487-4f83-4189-e405-ff931c8c024d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ë„ˆëŠ” ìš”ë¦¬ì‚¬ì•¼. ë‚´ê°€ ê°€ì§„ ì¬ë£Œë“¤ì„ ê°–ê³  ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ë¥¼ ì¶”ì²œí•˜ê³ , ê·¸ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ì œì‹œí•´ì¤˜.\n",
            "ë‚´ê°€ ê°€ì§„ ì¬ë£ŒëŠ” ì•„ë˜ì™€ ê°™ì•„.\n",
            "\n",
            "<ì¬ë£Œ>\n",
            "ìŒ€, ì¹˜í‚¨, ë„ˆêµ¬ë¦¬\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(davinch3(\n",
        "    prompt_template.format(\n",
        "        ì¬ë£Œ = 'ì–‘íŒŒ, ê³„ë€, ì‚¬ê³¼, ë¹µ'\n",
        "    )\n",
        "))"
      ],
      "metadata": {
        "id": "nSxX_4auG4UM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "5e082c8f-d54e-446b-83b8-02b690beacd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'prompt_template' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-687b45a26cb7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m print(davinch3(\n\u001b[0;32m----> 2\u001b[0;31m     prompt_template.format(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mì¬ë£Œ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ì–‘íŒŒ, ê³„ë€, ì‚¬ê³¼, ë¹µ'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     )\n\u001b[1;32m      5\u001b[0m ))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'prompt_template' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  ChatGPTì™€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ í™œìš©í•˜ì—¬ ëŒ€í™”í•´ë³´ê¸°"
      ],
      "metadata": {
        "id": "Ea5k-T2KacpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ],
      "metadata": {
        "id": "9yRP_2-aR9yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "# âœ… í…œí”Œë¦¿ ìˆ˜ì •: ì¬ë£Œëª©ë¡ë§Œ ë°›ìŒ\n",
        "template = \"\"\"\n",
        "ë„ˆëŠ” ìš”ë¦¬ì‚¬ì•¼. ë‚´ê°€ ê°€ì§„ ì¬ë£Œë“¤ì„ ê°–ê³  ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ë¥¼ ì¶”ì²œí•˜ê³ , ê·¸ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ì œì‹œí•´ì¤˜.\n",
        "ë‚´ê°€ ê°€ì§„ ì¬ë£ŒëŠ” ì•„ë˜ì™€ ê°™ì•„.\n",
        "\n",
        "<ì¬ë£Œ>\n",
        "{ì¬ë£Œëª©ë¡}\n",
        "\"\"\"\n",
        "\n",
        "chatgpt = ChatOpenAI(temperature=0)\n",
        "\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "\n",
        "human_template = \"{ì¬ë£Œëª©ë¡}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "\n",
        "# âœ… ì¬ë£Œë³„ ìˆ˜ëŸ‰ ì¡°í•© í›„ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
        "ì¬ë£Œë“¤ = [\"ì–‘íŒŒ\", \"ê³„ë€\", \"ì‚¬ê³¼\", \"ë¹µ\"]\n",
        "ìˆ˜ëŸ‰ë“¤ = [1, 2, 2, 1]\n",
        "\n",
        "ì¬ë£Œëª©ë¡ = \"\\n\".join(f\"{ì¬ë£Œ} {ìˆ˜ëŸ‰}ê°œ\" for ì¬ë£Œ, ìˆ˜ëŸ‰ in zip(ì¬ë£Œë“¤, ìˆ˜ëŸ‰ë“¤))\n",
        "\n",
        "# âœ… í¬ë§·íŒ…í•´ì„œ ì¶œë ¥\n",
        "#print(chat_prompt.format_prompt(ì¬ë£Œëª©ë¡=ì¬ë£Œëª©ë¡).to_messages())\n",
        "\n",
        "print(ì¬ë£Œëª©ë¡)\n",
        "\n",
        "answer = chatgpt(chat_prompt.format_prompt(ì¬ë£Œëª©ë¡=ì¬ë£Œëª©ë¡).to_messages())\n",
        "print(answer)\n",
        "#print(answer.content)\n"
      ],
      "metadata": {
        "id": "7jgLtLMPHKI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "806804b2-7985-43d3-efe7-c711de7007df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì–‘íŒŒ 1ê°œ\n",
            "ê³„ë€ 2ê°œ\n",
            "ì‚¬ê³¼ 2ê°œ\n",
            "ë¹µ 1ê°œ\n",
            "ê°€ì§€ê³  ê³„ì‹  ì¬ë£Œë¡œëŠ” \"ê³¼ì¼ ìƒëŸ¬ë“œì™€ ê³„ë€ í† ìŠ¤íŠ¸\"ë¥¼ ë§Œë“¤ì–´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”? \n",
            "\n",
            "**ê³¼ì¼ ìƒëŸ¬ë“œì™€ ê³„ë€ í† ìŠ¤íŠ¸ ë ˆì‹œí”¼:**\n",
            "\n",
            "**ê³¼ì¼ ìƒëŸ¬ë“œ ì¬ë£Œ:**\n",
            "- ì‚¬ê³¼ 1ê°œ (ë‚˜ë¨¸ì§€ 1ê°œëŠ” ê³„ë€ í† ìŠ¤íŠ¸ì— í™œìš©)\n",
            "- ì–‘íŒŒ 1/4ê°œ\n",
            "- ë¹µ 1/2ê°œ\n",
            "\n",
            "**ê³¼ì¼ ìƒëŸ¬ë“œ ë§Œë“œëŠ” ë²•:**\n",
            "1. ë¨¼ì € ì–‘íŒŒë¥¼ ì–‡ê²Œ ì±„ ì°ì–´ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
            "2. í•œ ê°œì˜ ì‚¬ê³¼ë¥¼ ê»ì§ˆì„ ë²—ê¸°ê³  ì‘ì€ ì¡°ê°ìœ¼ë¡œ ì°ì–´ì¤ë‹ˆë‹¤.\n",
            "3. ê·¸ ë‹¤ìŒ, ì¤€ë¹„í•œ ì–‘íŒŒì™€ ì‚¬ê³¼ë¥¼ ë³¼ì— ë„£ê³  ì„ì–´ì¤ë‹ˆë‹¤.\n",
            "\n",
            "**ê³„ë€ í† ìŠ¤íŠ¸ ì¬ë£Œ:**\n",
            "- ê³„ë€ 2ê°œ\n",
            "- ì‚¬ê³¼ 1ê°œ\n",
            "- ë¹µ 1/2ê°œ\n",
            "\n",
            "**ê³„ë€ í† ìŠ¤íŠ¸ ë§Œë“œëŠ” ë²•:**\n",
            "1. ê³„ë€ 2ê°œë¥¼ ê·¸ë¦‡ì— ë„£ê³  ì˜ í’€ì–´ì¤ë‹ˆë‹¤.\n",
            "2. íŒ¬ì— ê¸°ë¦„ì„ ë‘ë¥´ê³  ê³„ë€ì„ ë¶€ì–´ ê³„ë€í”„ë¼ì´ë¥¼ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.\n",
            "3. ë¹µì„ í† ìŠ¤í„°ì— êµ¬ì›Œì¤ë‹ˆë‹¤.\n",
            "4. êµ¬ìš´ ë¹µ ìœ„ì— ê³„ë€í”„ë¼ì´ì™€ ì–‘íŒŒ, ì‚¬ê³¼ë¥¼ ì–¹ì–´ ì™„ì„±í•©ë‹ˆë‹¤.\n",
            "\n",
            "ê³¼ì¼ ìƒëŸ¬ë“œì™€ ê³„ë€ í† ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì¦ê¸°ë©´ ê±´ê°•í•˜ê³  ë§›ìˆëŠ” í•œ ë¼ ì‹ì‚¬ê°€ ì™„ì„±ë  ê²ƒì…ë‹ˆë‹¤. ë§›ìˆê²Œ ë“œì„¸ìš”! ğŸ³ğŸğŸğŸ¥—\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(3) Few-shot ì˜ˆì œë¥¼ í†µí•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"
      ],
      "metadata": {
        "id": "LSEhdhkRazTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few-shotì´ë€, ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ê²°ê³¼ë¬¼ì„ ì¶œë ¥í•  ë•Œ ì˜ˆì‹œ ê²°ê³¼ë¬¼ì„ ì œì‹œí•¨ìœ¼ë¡œì¨ ì›í•˜ëŠ” ê²°ê³¼ë¬¼ë¡œ ìœ ë„í•˜ëŠ” ë°©ë²•ë¡ ì…ë‹ˆë‹¤.\n",
        "\n",
        "LLM ì—­ì‹œ, Few-shot ì˜ˆì œë¥¼ ì œê³µí•˜ë©´ ì˜ˆì œì™€ ìœ ì‚¬í•œ í˜•íƒœì˜ ê²°ê³¼ë¬¼ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "ë‚´ê°€ ì›í•˜ëŠ” ê²°ê³¼ë¬¼ì˜ í˜•íƒœê°€ íŠ¹ìˆ˜í•˜ê±°ë‚˜, êµ¬ì¡°í™”ëœ ë‹µë³€ì„ ì›í•  ê²½ìš°, ê²°ê³¼ë¬¼ì˜ ì˜ˆì‹œë¥¼ ìˆ˜ ê°œ ì œì‹œí•¨ìœ¼ë¡œì¨ ê²°ê³¼ë¬¼ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "oXkGkd_Xa5o6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "examples = [\n",
        "  {\n",
        "    \"question\": \"ì•„ì´ìœ ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\",\n",
        "    \"answer\":\n",
        "\"\"\"\n",
        "ì•„: ì•„ì´ìœ ëŠ”\n",
        "ì´: ì´ëŸ° ê°•ì˜ë¥¼ ë“¤ì„ ì´\n",
        "ìœ : ìœ ê°€ ì—†ë‹¤.\n",
        "\"\"\"\n",
        "  },\n",
        "\n",
        "  {\n",
        "    \"question\": \"ê¹€ë¯¼ìˆ˜ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\",\n",
        "    \"answer\":\n",
        "\"\"\"\n",
        "ê¹€: ê¹€ì¹˜ëŠ” ë§›ìˆë‹¤\n",
        "ë¯¼: ë¯¼ë‹¬íŒ½ì´ë„ ì¢‹ì•„í•˜ëŠ” ê¹€ì¹˜!\n",
        "ìˆ˜: ìˆ˜ì–µì„ ì¤˜ë„ ê¹€ì¹˜ëŠ” ë‚´êº¼!\n",
        "\"\"\"\n",
        "  }\n",
        "]"
      ],
      "metadata": {
        "id": "P71OBMpBVPY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompt = PromptTemplate(input_variables=[\"question\", \"answer\"], template=\"Question: {question}\\n{answer}\")\n",
        "\n",
        "print(example_prompt.format(**examples[0]))"
      ],
      "metadata": {
        "id": "vYoqJvxlbbLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344f97da-93bb-412a-d93d-8391e8f77f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: ì•„ì´ìœ ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\n",
            "\n",
            "ì•„: ì•„ì´ìœ ëŠ”\n",
            "ì´: ì´ëŸ° ê°•ì˜ë¥¼ ë“¤ì„ ì´\n",
            "ìœ : ìœ ê°€ ì—†ë‹¤.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    suffix=\"Question: {input}\",\n",
        "    input_variables=[\"input\"]\n",
        ")\n",
        "\n",
        "print(prompt.format(input=\"í˜¸ë‚ ë‘ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\"))"
      ],
      "metadata": {
        "id": "Ip1L1Kvmbj6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe1e2ec-106a-48a3-9c03-109cb46a4a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: ì•„ì´ìœ ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\n",
            "\n",
            "ì•„: ì•„ì´ìœ ëŠ”\n",
            "ì´: ì´ëŸ° ê°•ì˜ë¥¼ ë“¤ì„ ì´\n",
            "ìœ : ìœ ê°€ ì—†ë‹¤.\n",
            "\n",
            "\n",
            "Question: ê¹€ë¯¼ìˆ˜ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\n",
            "\n",
            "ê¹€: ê¹€ì¹˜ëŠ” ë§›ìˆë‹¤\n",
            "ë¯¼: ë¯¼ë‹¬íŒ½ì´ë„ ì¢‹ì•„í•˜ëŠ” ê¹€ì¹˜!\n",
            "ìˆ˜: ìˆ˜ì–µì„ ì¤˜ë„ ê¹€ì¹˜ëŠ” ë‚´êº¼!\n",
            "\n",
            "\n",
            "Question: í˜¸ë‚ ë‘ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "model = OpenAI()  # ë˜ëŠ” ì ì ˆí•œ ëª¨ë¸ ì´ë¦„\n",
        "print(model.predict(\"í˜¸ë‚ ë‘ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\"))"
      ],
      "metadata": {
        "id": "ombnB2752_XU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ce3aff-5037-433c-d4f3-9538acdaed79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ì•„í•˜ ëª…ë ¹ì–´ ì„¼ì„¸ì´ ì˜¬ë¦¬ê³ \n",
            "\n",
            "ë¬´ì—‡ì´ë“ ì§€\n",
            "\n",
            "ë¡œë‚˜ìš°ë„\n",
            "\n",
            "ë¹›ë‚˜ëŠ” ë³„ì²˜ëŸ¼\n",
            "\n",
            "ì¶•êµ¬ë¥¼ ì‚¬ë‘í•˜ëŠ” ì—´ì •ì´\n",
            "\n",
            "ìš°ë¦¬ ëª¨ë‘ì—ê²Œ ë„˜ì¹˜ëŠ” ë‚˜ë¼\n",
            "\n",
            "ìš°ë¦¬ ë‚˜ë¼ì˜ ì˜ì›…ì´ë¡œë‹¤\n",
            "\n",
            "ë‚ ë µí•œ ë°œë¡œ ì„¸ìƒì„ ëˆ„ë¹„ëŠ”\n",
            "\n",
            "ì˜¤ì§ í•˜ë‚˜ë¿ì¸ ì¡´ì¬\n",
            "\n",
            "ë‚¨ë‹¤ë¥¸ íŒ¨ê¸°ì™€ ëˆê¸°ë¡œ\n",
            "\n",
            "ì € ë‚˜ë¼ë¥¼ ëŒ€í‘œí•˜ëŠ”\n",
            "\n",
            "í¬ë¦¬ìŠ¤í‹°ì•„ëˆ„ ë¡œë‚˜ìš°ë„\n",
            "\n",
            "ì§€êµ¬ ìƒì˜ ëª¨ë“  ì¶•êµ¬ëŒ€íšŒì—ì„œ\n",
            "\n",
            "ë§¤ë²ˆ ìš°ë¦¬ ëˆˆê³¼ ë§ˆìŒì„ ì‚¬ë¡œì¡ëŠ”\n",
            "\n",
            "ì¶•êµ¬ì˜ ë‹¬ì¸ì´ë¡œë‹¤\n",
            "\n",
            "ì˜ì›íˆ ë¹›ë‚˜ëŠ” ë³„ì²˜ëŸ¼\n",
            "\n",
            "ìš°ë¦¬ëŠ” ê·¸ë¥¼ ì‚¬ë‘í•˜ë©°\n",
            "\n",
            "ëŠ˜ ê·¸ì˜ ë¬´ëŒ€ ìœ„ë¥¼ ì‘ì›í•  ê²ƒì´ë‹¤\n",
            "\n",
            "í¬ë¦¬ìŠ¤í‹°ì•„ëˆ„ ë¡œë‚˜ìš°ë„\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model(\n",
        "    prompt.format(input=\"í˜¸ë‚ ë‘ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\")\n",
        "))"
      ],
      "metadata": {
        "id": "kOwffrVsdADU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed7985e-c872-4db3-ec07-41a08ca33c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "í˜¸: í˜¸ë–¡ë„ ì¢‹ì§€ë§Œ\n",
            "ë‚ : ë‚ ì”¨ê°€ ë”°ëœ»í•´ì§€ë©´\n",
            "ë‘: ë‘ë¶€ê¹Œì§€ ë¨¹ê³  ì‹¶ì€ ë‚ ì´ë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (4) Example Selectorë¥¼ ì´ìš©í•œ ë™ì  Few-shot ëŸ¬ë‹"
      ],
      "metadata": {
        "id": "9bzF-tKHiw3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few-shot ì˜ˆì œë¥¼ ë™ì ìœ¼ë¡œ ì…ë ¥í•˜ê³  ì‹¶ì€ ê²½ìš°, Example Selectorë¥¼ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "LLMì´ ì—¬ëŸ¬ ì‘ì—…ì„ ìˆ˜í–‰í•˜ë„ë¡ ë§Œë“¤ë˜ ë‚´ê°€ ì›í•˜ëŠ” ë²”ìœ„ì˜ ëŒ€ë‹µì„ ì¶œë ¥í•˜ë„ë¡ í•˜ë ¤ë©´ ì‚¬ìš©ìì˜ ì…ë ¥ì— ë™ì ìœ¼ë¡œ ë°˜ì‘í•´ì•¼ í•©ë‹ˆë‹¤.ì´ì™€ ë™ì‹œì—, ì˜ˆì œë¥¼ ëª¨ë‘ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì ì ˆí•œ ì˜ˆì‹œë§Œ í¬í•¨í•˜ë„ë¡ í•¨ìœ¼ë¡œì¨ ì…ë ¥ promptì˜ ê¸¸ì´ë¥¼ ì œí•œí•˜ê³ , ì´ë¥¼ í†µí•´ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì§€ ì•Šë„ë¡ ì¡°ì ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "SFriPzdEi-6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"output\"],\n",
        "    template=\"Input: {input}\\nOutput: {output}\",\n",
        ")\n",
        "\n",
        "# These are a lot of examples of a pretend task of creating antonyms.\n",
        "examples = [\n",
        "    {\"input\": \"í–‰ë³µ\", \"output\": \"ìŠ¬í””\"},\n",
        "    {\"input\": \"í¥ë¯¸\", \"output\": \"ì§€ë£¨\"},\n",
        "    {\"input\": \"ë¶ˆì•ˆ\", \"output\": \"ì•ˆì •\"},\n",
        "    {\"input\": \"ê¸´ ê¸°ì°¨\", \"output\": \"ì§§ì€ ê¸°ì°¨\"},\n",
        "    {\"input\": \"í° ê³µ\", \"output\": \"ì‘ì€ ê³µ\"},\n",
        "]"
      ],
      "metadata": {
        "id": "ImuHUY24i7E8",
        "outputId": "5a3d07b6-a38d-4857-860f-9acc4c6682fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "Module langchain_community.vectorstores not found. Please install langchain-community to access this module. You can install it using `pip install -U langchain-community`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/_api/module_import.py\u001b[0m in \u001b[0;36mimport_by_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-542d8f082cb9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexample_selector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSemanticSimilarityExampleSelector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChroma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFewShotPromptTemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/vectorstores/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;34m\"\"\"Look up attributes dynamically.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_import_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/_api/module_import.py\u001b[0m in \u001b[0;36mimport_by_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"langchain_community\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                     raise ModuleNotFoundError(\n\u001b[0m\u001b[1;32m     73\u001b[0m                         \u001b[0;34mf\"Module {new_module} not found. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                         \u001b[0;34m\"Please install langchain-community to access this module. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: Module langchain_community.vectorstores not found. Please install langchain-community to access this module. You can install it using `pip install -U langchain-community`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "hZdsaKvSk2hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
        "    # This is the list of examples available to select from.\n",
        "    examples,\n",
        "    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
        "    OpenAIEmbeddings(),\n",
        "    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
        "    Chroma,\n",
        "    # This is the number of examples to produce.\n",
        "    k=1\n",
        ")\n",
        "similar_prompt = FewShotPromptTemplate(\n",
        "    # We provide an ExampleSelector instead of examples.\n",
        "    example_selector=example_selector,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"ì£¼ì–´ì§„ ì…ë ¥ì— ëŒ€í•´ ë°˜ëŒ€ì˜ ì˜ë¯¸ë¥¼ ê°€ì§„ ë‹¨ì–´ë¥¼ ì¶œë ¥í•´ì¤˜\",\n",
        "    suffix=\"Input: {ë‹¨ì–´}\\nOutput:\",\n",
        "    input_variables=[\"ë‹¨ì–´\"],\n",
        ")"
      ],
      "metadata": {
        "id": "7fR63b8OkkT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input is a feeling, so should select the happy/sad example\n",
        "print(similar_prompt.format(ë‹¨ì–´=\"ë¬´ì„œìš´\"))"
      ],
      "metadata": {
        "id": "IBLqJJ1Glmim",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d7f80e8-055c-42eb-e452-cb157d469908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì£¼ì–´ì§„ ì…ë ¥ì— ëŒ€í•´ ë°˜ëŒ€ì˜ ì˜ë¯¸ë¥¼ ê°€ì§„ ë‹¨ì–´ë¥¼ ì¶œë ¥í•´ì¤˜\n",
            "\n",
            "Input: ë¶ˆì•ˆ\n",
            "Output: ì•ˆì •\n",
            "\n",
            "Input: ë¬´ì„œìš´\n",
            "Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input is a feeling, so should select the happy/sad example\n",
        "print(similar_prompt.format(ë‹¨ì–´=\"í° ë¹„í–‰ê¸°\"))"
      ],
      "metadata": {
        "id": "4PMPa7oAk1P5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de03e2f-68c6-44fc-cb88-1d79a12d725e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì£¼ì–´ì§„ ì…ë ¥ì— ëŒ€í•´ ë°˜ëŒ€ì˜ ì˜ë¯¸ë¥¼ ê°€ì§„ ë‹¨ì–´ë¥¼ ì¶œë ¥í•´ì¤˜\n",
            "\n",
            "Input: ê¸´ ê¸°ì°¨\n",
            "Output: ì§§ì€ ê¸°ì°¨\n",
            "\n",
            "Input: í° ë¹„í–‰ê¸°\n",
            "Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"í° ë¹„í–‰ê¸°\"\n",
        "\n",
        "print(davinch3(\n",
        "    similar_prompt.format(ë‹¨ì–´=query)\n",
        "))"
      ],
      "metadata": {
        "id": "QVhHxGDIl9vO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6ecc76f-286d-49f9-e602-ac02f7c27420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ì‘ì€ ë¹„í–‰ê¸°\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (5) Output Parserë¥¼ í™œìš©í•œ ì¶œë ¥ê°’ ì¡°ì •"
      ],
      "metadata": {
        "id": "voHpTEbCtZbd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLMì˜ ë‹µë³€ì„ ë‚´ê°€ ì›í•˜ëŠ” í˜•íƒœë¡œ ê³ ì •í•˜ê³  ì‹¶ë‹¤ë©´ OutputParser í•¨ìˆ˜ë¥¼ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¦¬ìŠ¤íŠ¸, JSON í˜•íƒœ ë“± ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë‹µë³€ì„ ê³ ì •í•˜ì—¬ ì¶œë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "OeOagtrYtddg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "m3kZmxYPndZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = CommaSeparatedListOutputParser()"
      ],
      "metadata": {
        "id": "WCv9v_o2tpns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format_instructions = output_parser.get_format_instructions()\n",
        "format_instructions"
      ],
      "metadata": {
        "id": "YszrHErKuGSr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d23e14ec-da84-43aa-ca48-d3040e9441c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your response should be a list of comma separated values, eg: `foo, bar, baz`'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    template=\"{ì£¼ì œ} 5ê°œë¥¼ ì¶”ì²œí•´ì¤˜.\\n{format_instructions}\",\n",
        "    input_variables=[\"ì£¼ì œ\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions}\n",
        ")"
      ],
      "metadata": {
        "id": "9DwQ7cWptq5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "n2o_FERKtr7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_input = prompt.format(ì£¼ì œ=\"ì˜í™”\")\n",
        "output = model(_input)"
      ],
      "metadata": {
        "id": "JogXFdLrttG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Z0nSEvFhE4IS",
        "outputId": "b23a916e-70ce-4a5f-be43-7db395ddb50a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nì•„ì´ ìŠ¤íƒ€ì¼, ìŠ¤íƒ€ ì›Œì¦ˆ: ê¹¨ì–´ë‚œ í¬ìŠ¤, ì—”ë“œê²Œì„, ìŠ¤íŒŒì´ë”ë§¨: í™ˆì»¤ë°, ì—‘ìŠ¤ë§¨: ë°ì´ì¦ˆ ì˜¤ë¸Œ í“¨ì²˜, ì–´ë²¤ì ¸ìŠ¤: ì—”ë“œê²Œì„'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser.parse(output)"
      ],
      "metadata": {
        "id": "YJSP5zCztuPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "389815d4-cdb6-4ef6-be09-3147f02172d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ì•„ì´ ìŠ¤íƒ€ì¼',\n",
              " 'ìŠ¤íƒ€ ì›Œì¦ˆ: ê¹¨ì–´ë‚œ í¬ìŠ¤',\n",
              " 'ì—”ë“œê²Œì„',\n",
              " 'ìŠ¤íŒŒì´ë”ë§¨: í™ˆì»¤ë°',\n",
              " 'ì—‘ìŠ¤ë§¨: ë°ì´ì¦ˆ ì˜¤ë¸Œ í“¨ì²˜',\n",
              " 'ì–´ë²¤ì ¸ìŠ¤: ì—”ë“œê²Œì„']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gnNOKXV3tvX5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csh-scl/LLM-Study/blob/main/PromptTemplate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai langchain langchain-openai\n",
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "EBFyoFPb-_7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d76d9fb4-9c41-46b5-ea2c-0aae83e3878a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.62)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.42)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qhh9fyI8-d9v"
      },
      "outputs": [],
      "source": [
        "#API KEY 저장을 위한 os 라이브러리 호출\n",
        "import os\n",
        "\n",
        "#기본 LLM 로드를 위한 라이브러리 호출\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "#채팅 LLM 로드를 위한 라이브러리 호출\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#OPENAI API키 저장\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'Your API Key'"
      ],
      "metadata": {
        "id": "9F6f494n-IWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------"
      ],
      "metadata": {
        "id": "DczHm9qI994V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Davinch-003 모델 설정하기"
      ],
      "metadata": {
        "id": "THkva8fB-C0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "davinch3 = OpenAI(\n",
        "    model_name=\"text-davinci-003\",\n",
        "    max_tokens = 1000\n",
        ")"
      ],
      "metadata": {
        "id": "uqur0akRHi0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ccc734f-87d2-458c-9d89-07c177c83179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-349a1428bdbb>:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  davinch3 = OpenAI(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (1) 프롬프트 템플릿 맛보기"
      ],
      "metadata": {
        "id": "QhCfB_lQ-uqx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "프롬프트 템플릿은 크게 2가지가 존재합니다.\n",
        "1. Prompt Template\n",
        "2. Chat Prompt Template\n",
        "\n",
        "1번 Prompt Template은 일반적인 프롬프트 템플릿을 생성할때 활용합니다.\n",
        "\n",
        "2번 Chat Prompt Template은 채팅 LLM에 프롬프트를 전달하는 데에 활용할 수 있는 특화 프롬프트 템플릿입니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "LrfEmGR5Ctbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
        "\n",
        "#프롬프트 템플릿을 통해 매개변수 삽입 가능한 문자열로 변환\n",
        "string_prompt = PromptTemplate.from_template(\"tell me a joke about {subject} {price}\")\n",
        "\n",
        "#매개변수 삽입한 결과를 string_prompt_value에 할당\n",
        "string_prompt_value = string_prompt.format_prompt(subject=\"soccer\", price = 10000)\n",
        "\n",
        "#채팅LLM이 아닌 LLM과 대화할 때 필요한 프롬프트 = string prompt\n",
        "string_prompt_value"
      ],
      "metadata": {
        "id": "-bX3Wvsy-tyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e6169d7-5814-42fe-9da5-a69a67b3933b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text='tell me a joke about soccer 10000')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to_string() 함수를 통해 prompt template으로 생성한 문장 raw_text 반환 가능\n",
        "print(string_prompt_value.to_string())"
      ],
      "metadata": {
        "id": "6F3GCMX7-7j8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "457a2145-15b9-4a62-a106-19ecf9631350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tell me a joke about soccer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt = ChatPromptTemplate.from_template(\"tell me a joke about {subject}\")\n",
        "chat_prompt_value = chat_prompt.format_prompt(subject=\"soccer\")\n",
        "chat_prompt_value"
      ],
      "metadata": {
        "id": "vylmSAk2_dfk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c920c9b-5020-4bb6-89b5-5e5c2ad925a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content='tell me a joke about soccer', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "string_prompt = PromptTemplate.from_template(\"Could you recommend {subject} nearby {price}?\")\n",
        "string_prompt_value = string_prompt.format_prompt(subject= \"food\", price=10000)\n",
        "\n",
        "# OpenAI LLM 생성 (API 키는 환경변수에서 자동으로 인식)\n",
        "llm = OpenAI()\n",
        "\n",
        "# 프롬프트 실행\n",
        "response = llm.invoke(string_prompt_value.to_string())\n",
        "\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "nIma_sYw6G95",
        "outputId": "761ca53b-07e7-4c1d-f943-42b008f09b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'food' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5a577bf47dba>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 프롬프트 템플릿 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstring_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could you recommend {subject} nearby {price}?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstring_prompt_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_prompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# OpenAI LLM 생성 (API 키는 환경변수에서 자동으로 인식)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'food' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt_value.to_string()"
      ],
      "metadata": {
        "id": "47q4Uy2y_bM8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd7899dc-bbb7-4b93-db6f-4e6b7c047b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: tell me a joke about soccer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (2) 프롬프트 템플릿 활용해보기"
      ],
      "metadata": {
        "id": "jVF-pxeUE4JI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "반복적인 프롬프트를 삽입해야하는 경우, Prompt Template를 통해 간편하게 LLM을 활용할 수 있습니다."
      ],
      "metadata": {
        "id": "RIoNBQ_HFNlm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- GPT-3와 프롬프트 템플릿을 활용하여 대화해보기"
      ],
      "metadata": {
        "id": "25dmtYfJajHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "너는 요리사야. 내가 가진 재료들을 갖고 만들 수 있는 요리를 추천하고, 그 요리의 레시피를 제시해줘.\n",
        "내가 가진 재료는 아래와 같아.\n",
        "\n",
        "<재료>\n",
        "{재료}{수량}개\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "p1urKI18_bxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt_template.format(재료 = '쌀, 치킨, 너구리'))"
      ],
      "metadata": {
        "id": "lhBbXyEWGGE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1832487-4f83-4189-e405-ff931c8c024d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "너는 요리사야. 내가 가진 재료들을 갖고 만들 수 있는 요리를 추천하고, 그 요리의 레시피를 제시해줘.\n",
            "내가 가진 재료는 아래와 같아.\n",
            "\n",
            "<재료>\n",
            "쌀, 치킨, 너구리\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(davinch3(\n",
        "    prompt_template.format(\n",
        "        재료 = '양파, 계란, 사과, 빵'\n",
        "    )\n",
        "))"
      ],
      "metadata": {
        "id": "nSxX_4auG4UM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "5e082c8f-d54e-446b-83b8-02b690beacd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'prompt_template' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-687b45a26cb7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m print(davinch3(\n\u001b[0;32m----> 2\u001b[0;31m     prompt_template.format(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0m재료\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'양파, 계란, 사과, 빵'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     )\n\u001b[1;32m      5\u001b[0m ))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'prompt_template' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  ChatGPT와 프롬프트 템플릿을 활용하여 대화해보기"
      ],
      "metadata": {
        "id": "Ea5k-T2KacpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ],
      "metadata": {
        "id": "9yRP_2-aR9yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "# ✅ 템플릿 수정: 재료목록만 받음\n",
        "template = \"\"\"\n",
        "너는 요리사야. 내가 가진 재료들을 갖고 만들 수 있는 요리를 추천하고, 그 요리의 레시피를 제시해줘.\n",
        "내가 가진 재료는 아래와 같아.\n",
        "\n",
        "<재료>\n",
        "{재료목록}\n",
        "\"\"\"\n",
        "\n",
        "chatgpt = ChatOpenAI(temperature=0)\n",
        "\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "\n",
        "human_template = \"{재료목록}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "\n",
        "# ✅ 재료별 수량 조합 후 문자열로 변환\n",
        "재료들 = [\"양파\", \"계란\", \"사과\", \"빵\"]\n",
        "수량들 = [1, 2, 2, 1]\n",
        "\n",
        "재료목록 = \"\\n\".join(f\"{재료} {수량}개\" for 재료, 수량 in zip(재료들, 수량들))\n",
        "\n",
        "# ✅ 포맷팅해서 출력\n",
        "#print(chat_prompt.format_prompt(재료목록=재료목록).to_messages())\n",
        "\n",
        "print(재료목록)\n",
        "\n",
        "answer = chatgpt(chat_prompt.format_prompt(재료목록=재료목록).to_messages())\n",
        "print(answer)\n",
        "#print(answer.content)\n"
      ],
      "metadata": {
        "id": "7jgLtLMPHKI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "806804b2-7985-43d3-efe7-c711de7007df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "양파 1개\n",
            "계란 2개\n",
            "사과 2개\n",
            "빵 1개\n",
            "가지고 계신 재료로는 \"과일 샐러드와 계란 토스트\"를 만들어보시는 건 어떨까요? \n",
            "\n",
            "**과일 샐러드와 계란 토스트 레시피:**\n",
            "\n",
            "**과일 샐러드 재료:**\n",
            "- 사과 1개 (나머지 1개는 계란 토스트에 활용)\n",
            "- 양파 1/4개\n",
            "- 빵 1/2개\n",
            "\n",
            "**과일 샐러드 만드는 법:**\n",
            "1. 먼저 양파를 얇게 채 썰어 준비합니다.\n",
            "2. 한 개의 사과를 껍질을 벗기고 작은 조각으로 썰어줍니다.\n",
            "3. 그 다음, 준비한 양파와 사과를 볼에 넣고 섞어줍니다.\n",
            "\n",
            "**계란 토스트 재료:**\n",
            "- 계란 2개\n",
            "- 사과 1개\n",
            "- 빵 1/2개\n",
            "\n",
            "**계란 토스트 만드는 법:**\n",
            "1. 계란 2개를 그릇에 넣고 잘 풀어줍니다.\n",
            "2. 팬에 기름을 두르고 계란을 부어 계란프라이를 만들어줍니다.\n",
            "3. 빵을 토스터에 구워줍니다.\n",
            "4. 구운 빵 위에 계란프라이와 양파, 사과를 얹어 완성합니다.\n",
            "\n",
            "과일 샐러드와 계란 토스트를 함께 즐기면 건강하고 맛있는 한 끼 식사가 완성될 것입니다. 맛있게 드세요! 🍳🍞🍎🥗\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(3) Few-shot 예제를 통한 프롬프트 템플릿"
      ],
      "metadata": {
        "id": "LSEhdhkRazTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few-shot이란, 딥러닝 모델이 결과물을 출력할 때 예시 결과물을 제시함으로써 원하는 결과물로 유도하는 방법론입니다.\n",
        "\n",
        "LLM 역시, Few-shot 예제를 제공하면 예제와 유사한 형태의 결과물을 출력합니다.\n",
        "\n",
        "내가 원하는 결과물의 형태가 특수하거나, 구조화된 답변을 원할 경우, 결과물의 예시를 수 개 제시함으로써 결과물의 품질을 향상시킬 수 있습니다."
      ],
      "metadata": {
        "id": "oXkGkd_Xa5o6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "examples = [\n",
        "  {\n",
        "    \"question\": \"아이유로 삼행시 만들어줘\",\n",
        "    \"answer\":\n",
        "\"\"\"\n",
        "아: 아이유는\n",
        "이: 이런 강의를 들을 이\n",
        "유: 유가 없다.\n",
        "\"\"\"\n",
        "  },\n",
        "\n",
        "  {\n",
        "    \"question\": \"김민수로 삼행시 만들어줘\",\n",
        "    \"answer\":\n",
        "\"\"\"\n",
        "김: 김치는 맛있다\n",
        "민: 민달팽이도 좋아하는 김치!\n",
        "수: 수억을 줘도 김치는 내꺼!\n",
        "\"\"\"\n",
        "  }\n",
        "]"
      ],
      "metadata": {
        "id": "P71OBMpBVPY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompt = PromptTemplate(input_variables=[\"question\", \"answer\"], template=\"Question: {question}\\n{answer}\")\n",
        "\n",
        "print(example_prompt.format(**examples[0]))"
      ],
      "metadata": {
        "id": "vYoqJvxlbbLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344f97da-93bb-412a-d93d-8391e8f77f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: 아이유로 삼행시 만들어줘\n",
            "\n",
            "아: 아이유는\n",
            "이: 이런 강의를 들을 이\n",
            "유: 유가 없다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    suffix=\"Question: {input}\",\n",
        "    input_variables=[\"input\"]\n",
        ")\n",
        "\n",
        "print(prompt.format(input=\"호날두로 삼행시 만들어줘\"))"
      ],
      "metadata": {
        "id": "Ip1L1Kvmbj6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe1e2ec-106a-48a3-9c03-109cb46a4a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: 아이유로 삼행시 만들어줘\n",
            "\n",
            "아: 아이유는\n",
            "이: 이런 강의를 들을 이\n",
            "유: 유가 없다.\n",
            "\n",
            "\n",
            "Question: 김민수로 삼행시 만들어줘\n",
            "\n",
            "김: 김치는 맛있다\n",
            "민: 민달팽이도 좋아하는 김치!\n",
            "수: 수억을 줘도 김치는 내꺼!\n",
            "\n",
            "\n",
            "Question: 호날두로 삼행시 만들어줘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "model = OpenAI()  # 또는 적절한 모델 이름\n",
        "print(model.predict(\"호날두로 삼행시 만들어줘\"))"
      ],
      "metadata": {
        "id": "ombnB2752_XU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ce3aff-5037-433c-d4f3-9538acdaed79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "아하 명령어 센세이 올리고\n",
            "\n",
            "무엇이든지\n",
            "\n",
            "로나우도\n",
            "\n",
            "빛나는 별처럼\n",
            "\n",
            "축구를 사랑하는 열정이\n",
            "\n",
            "우리 모두에게 넘치는 나라\n",
            "\n",
            "우리 나라의 영웅이로다\n",
            "\n",
            "날렵한 발로 세상을 누비는\n",
            "\n",
            "오직 하나뿐인 존재\n",
            "\n",
            "남다른 패기와 끈기로\n",
            "\n",
            "저 나라를 대표하는\n",
            "\n",
            "크리스티아누 로나우도\n",
            "\n",
            "지구 상의 모든 축구대회에서\n",
            "\n",
            "매번 우리 눈과 마음을 사로잡는\n",
            "\n",
            "축구의 달인이로다\n",
            "\n",
            "영원히 빛나는 별처럼\n",
            "\n",
            "우리는 그를 사랑하며\n",
            "\n",
            "늘 그의 무대 위를 응원할 것이다\n",
            "\n",
            "크리스티아누 로나우도\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model(\n",
        "    prompt.format(input=\"호날두로 삼행시 만들어줘\")\n",
        "))"
      ],
      "metadata": {
        "id": "kOwffrVsdADU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed7985e-c872-4db3-ec07-41a08ca33c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "호: 호떡도 좋지만\n",
            "날: 날씨가 따뜻해지면\n",
            "두: 두부까지 먹고 싶은 날이다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (4) Example Selector를 이용한 동적 Few-shot 러닝"
      ],
      "metadata": {
        "id": "9bzF-tKHiw3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few-shot 예제를 동적으로 입력하고 싶은 경우, Example Selector를 활용할 수 있습니다.\n",
        "\n",
        "LLM이 여러 작업을 수행하도록 만들되 내가 원하는 범위의 대답을 출력하도록 하려면 사용자의 입력에 동적으로 반응해야 합니다.이와 동시에, 예제를 모두 학습시키는 것이 아니라 적절한 예시만 포함하도록 함으로써 입력 prompt의 길이를 제한하고, 이를 통해 오류가 발생하지 않도록 조절할 수 있습니다."
      ],
      "metadata": {
        "id": "SFriPzdEi-6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"output\"],\n",
        "    template=\"Input: {input}\\nOutput: {output}\",\n",
        ")\n",
        "\n",
        "# These are a lot of examples of a pretend task of creating antonyms.\n",
        "examples = [\n",
        "    {\"input\": \"행복\", \"output\": \"슬픔\"},\n",
        "    {\"input\": \"흥미\", \"output\": \"지루\"},\n",
        "    {\"input\": \"불안\", \"output\": \"안정\"},\n",
        "    {\"input\": \"긴 기차\", \"output\": \"짧은 기차\"},\n",
        "    {\"input\": \"큰 공\", \"output\": \"작은 공\"},\n",
        "]"
      ],
      "metadata": {
        "id": "ImuHUY24i7E8",
        "outputId": "5a3d07b6-a38d-4857-860f-9acc4c6682fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "Module langchain_community.vectorstores not found. Please install langchain-community to access this module. You can install it using `pip install -U langchain-community`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/_api/module_import.py\u001b[0m in \u001b[0;36mimport_by_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-542d8f082cb9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexample_selector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSemanticSimilarityExampleSelector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChroma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFewShotPromptTemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/vectorstores/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;34m\"\"\"Look up attributes dynamically.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_import_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/_api/module_import.py\u001b[0m in \u001b[0;36mimport_by_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"langchain_community\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                     raise ModuleNotFoundError(\n\u001b[0m\u001b[1;32m     73\u001b[0m                         \u001b[0;34mf\"Module {new_module} not found. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                         \u001b[0;34m\"Please install langchain-community to access this module. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: Module langchain_community.vectorstores not found. Please install langchain-community to access this module. You can install it using `pip install -U langchain-community`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "hZdsaKvSk2hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
        "    # This is the list of examples available to select from.\n",
        "    examples,\n",
        "    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
        "    OpenAIEmbeddings(),\n",
        "    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
        "    Chroma,\n",
        "    # This is the number of examples to produce.\n",
        "    k=1\n",
        ")\n",
        "similar_prompt = FewShotPromptTemplate(\n",
        "    # We provide an ExampleSelector instead of examples.\n",
        "    example_selector=example_selector,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"주어진 입력에 대해 반대의 의미를 가진 단어를 출력해줘\",\n",
        "    suffix=\"Input: {단어}\\nOutput:\",\n",
        "    input_variables=[\"단어\"],\n",
        ")"
      ],
      "metadata": {
        "id": "7fR63b8OkkT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input is a feeling, so should select the happy/sad example\n",
        "print(similar_prompt.format(단어=\"무서운\"))"
      ],
      "metadata": {
        "id": "IBLqJJ1Glmim",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d7f80e8-055c-42eb-e452-cb157d469908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "주어진 입력에 대해 반대의 의미를 가진 단어를 출력해줘\n",
            "\n",
            "Input: 불안\n",
            "Output: 안정\n",
            "\n",
            "Input: 무서운\n",
            "Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input is a feeling, so should select the happy/sad example\n",
        "print(similar_prompt.format(단어=\"큰 비행기\"))"
      ],
      "metadata": {
        "id": "4PMPa7oAk1P5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de03e2f-68c6-44fc-cb88-1d79a12d725e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "주어진 입력에 대해 반대의 의미를 가진 단어를 출력해줘\n",
            "\n",
            "Input: 긴 기차\n",
            "Output: 짧은 기차\n",
            "\n",
            "Input: 큰 비행기\n",
            "Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"큰 비행기\"\n",
        "\n",
        "print(davinch3(\n",
        "    similar_prompt.format(단어=query)\n",
        "))"
      ],
      "metadata": {
        "id": "QVhHxGDIl9vO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6ecc76f-286d-49f9-e602-ac02f7c27420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 작은 비행기\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (5) Output Parser를 활용한 출력값 조정"
      ],
      "metadata": {
        "id": "voHpTEbCtZbd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM의 답변을 내가 원하는 형태로 고정하고 싶다면 OutputParser 함수를 활용할 수 있습니다. 리스트, JSON 형태 등 다양한 형식의 답변을 고정하여 출력할 수 있습니다."
      ],
      "metadata": {
        "id": "OeOagtrYtddg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "m3kZmxYPndZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = CommaSeparatedListOutputParser()"
      ],
      "metadata": {
        "id": "WCv9v_o2tpns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format_instructions = output_parser.get_format_instructions()\n",
        "format_instructions"
      ],
      "metadata": {
        "id": "YszrHErKuGSr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d23e14ec-da84-43aa-ca48-d3040e9441c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your response should be a list of comma separated values, eg: `foo, bar, baz`'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    template=\"{주제} 5개를 추천해줘.\\n{format_instructions}\",\n",
        "    input_variables=[\"주제\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions}\n",
        ")"
      ],
      "metadata": {
        "id": "9DwQ7cWptq5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "n2o_FERKtr7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_input = prompt.format(주제=\"영화\")\n",
        "output = model(_input)"
      ],
      "metadata": {
        "id": "JogXFdLrttG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Z0nSEvFhE4IS",
        "outputId": "b23a916e-70ce-4a5f-be43-7db395ddb50a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n아이 스타일, 스타 워즈: 깨어난 포스, 엔드게임, 스파이더맨: 홈커밍, 엑스맨: 데이즈 오브 퓨처, 어벤져스: 엔드게임'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser.parse(output)"
      ],
      "metadata": {
        "id": "YJSP5zCztuPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "389815d4-cdb6-4ef6-be09-3147f02172d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['아이 스타일',\n",
              " '스타 워즈: 깨어난 포스',\n",
              " '엔드게임',\n",
              " '스파이더맨: 홈커밍',\n",
              " '엑스맨: 데이즈 오브 퓨처',\n",
              " '어벤져스: 엔드게임']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gnNOKXV3tvX5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}